{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6708efea-c36a-466e-bb73-fde2cef02377",
   "metadata": {},
   "source": [
    "# Azure Machine Learning - AutoML Experiment using v2 SDK\n",
    "\n",
    "Sample here can be run from an Azure ML Compute Instance using the Python 3.10 - SDK v2 Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e123106c-a148-463c-9f9f-df107e5f7e89",
   "metadata": {},
   "source": [
    "### Retrieve source data from [GH Repo](https://github.com/ignavinuales/Battery_RUL_Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2ec54-6130-41d7-8f72-31a8692f0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the GitHub repository containing the Battery RUL Prediction project into the Jupyter notebook's workspace  \n",
    "! git clone https://github.com/ignavinuales/Battery_RUL_Prediction  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a8603b-b278-4691-8a3f-7e9955c6967e",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec11059-0069-4f9e-82a0-36c048a7f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages and modules  \n",
    "from azure.ai.ml import MLClient, Input, automl\n",
    "from azure.ai.ml.entities import Data, AmlCompute, Model, ModelPackage, CodeConfiguration, AzureMLOnlineInferencingServer, ManagedOnlineEndpoint, ManagedOnlineDeployment, Environment\n",
    "from azure.ai.ml.constants import AssetTypes  \n",
    "from azure.ai.ml import automl\n",
    "from azure.identity import DefaultAzureCredential  \n",
    "import mltable  \n",
    "import pandas as pd    \n",
    "import numpy as np    \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7bcfa5-15ad-4022-8cf9-3acd87f8a702",
   "metadata": {},
   "source": [
    "### Instantiate ml_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db43ec-f16b-443d-ab00-3509aed027d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLClient object from configuration file and DefaultAzureCredential  \n",
    "ml_client = MLClient.from_config(credential=DefaultAzureCredential())  \n",
    "\n",
    "# Print the MLClient object  \n",
    "print(ml_client)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cb8f05-54e3-4920-a019-b9a7591d7a49",
   "metadata": {},
   "source": [
    "### Create compute cluster for AutoML training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00683c2f-d786-4576-8269-14af63586d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the CPU compute target to be used or created  \n",
    "cpu_compute_target = \"cpu-cluster\"  \n",
    "  \n",
    "try:  \n",
    "    # Try to get the details of the specified compute target if it already exists  \n",
    "    ml_client.compute.get(cpu_compute_target)  \n",
    "except Exception:  \n",
    "    # If the compute target does not exist, catch the exception and create a new one  \n",
    "    print(\"Creating a new cpu compute target...\")  \n",
    "    # Define the compute target specifications such as name, VM size, and instance limits  \n",
    "    compute = AmlCompute(  \n",
    "        name=cpu_compute_target, size=\"STANDARD_D2_V2\", min_instances=0, max_instances=4  \n",
    "    )  \n",
    "    # Initiate the creation or update of the compute target and wait for the operation to complete  \n",
    "    ml_client.compute.begin_create_or_update(compute).result()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537de220-0864-4864-b6e2-c5b54aa7130d",
   "metadata": {},
   "source": [
    "### Split data into train/validation subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effdc309-47bb-4a11-ad73-45c08e6e948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in downloaded Battery Life directory that contain 'features' in their name  \n",
    "data_dir = './Battery_RUL_Prediction/Datasets/HNEI_Processed'  \n",
    "files = [os.path.join(data_dir, x) for x in os.listdir(data_dir) if 'features' in x]  \n",
    "  \n",
    "# Randomly select 2 files for validation and use the rest for training  \n",
    "validation_files = random.sample(files, 2)  \n",
    "train_files = [x for x in files if x not in validation_files]  \n",
    "  \n",
    "# Initialize an empty DataFrame for validation data  \n",
    "validation_df = pd.DataFrame()  \n",
    "# Loop through each file in the validation set, read the data, and concatenate it into the validation DataFrame  \n",
    "for f in validation_files:  \n",
    "    validation_df = pd.concat([validation_df, pd.read_csv(f)])  \n",
    "# Drop unnecessary columns from the validation DataFrame  \n",
    "validation_df = validation_df.drop(columns=['Unnamed: 0', 'Cycle_Index'])  \n",
    "  \n",
    "# Initialize an empty DataFrame for training data  \n",
    "train_df = pd.DataFrame()  \n",
    "# Loop through each file in the training set, read the data, and concatenate it into the training DataFrame  \n",
    "for f in train_files:  \n",
    "    train_df = pd.concat([train_df, pd.read_csv(f)])  \n",
    "# Drop unnecessary columns from the training DataFrame  \n",
    "train_df = train_df.drop(columns=['Unnamed: 0', 'Cycle_Index'])  \n",
    "  \n",
    "# Display the first few rows of the training DataFrame  \n",
    "print(train_df.head())  \n",
    "  \n",
    "# Create directories for storing processed validation and training data if they don't exist  \n",
    "os.makedirs('./validation', exist_ok=True)  \n",
    "os.makedirs('./train', exist_ok=True)  \n",
    "  \n",
    "# Save the processed validation and training DataFrames to CSV files  \n",
    "validation_df.to_csv('./validation/validation_data.csv', index=False)  \n",
    "train_df.to_csv('./train/train_data.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579e5b1-2e9f-4ae0-a8f5-afe2e3553991",
   "metadata": {},
   "source": [
    "### Register train/validation datasets into the Azure ML workspace for use in model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192bfe93-db7e-4711-a854-578c3b8cf37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name for the validation dataset  \n",
    "validation_dataset_name = 'VALIDATION_BatteryCycles'  \n",
    "  \n",
    "# Provide a description for the validation dataset  \n",
    "validation_dataset_description = 'Holdout dataset from battery cycle repo @https://github.com/ignavinuales/Battery_RUL_Prediction'  \n",
    "  \n",
    "# Specify the local path to save the validation dataset  \n",
    "validation_tbl_path = './validation'  \n",
    "  \n",
    "# Define the file path to the validation dataset CSV file  \n",
    "validation_paths = [{'file':'./validation/validation_data.csv'}]  \n",
    "  \n",
    "# Load the validation dataset from the CSV file into a MLTable  \n",
    "validation_tbl = mltable.from_delimited_files(paths=validation_paths)  \n",
    "  \n",
    "# Save the MLTable to the specified path  \n",
    "validation_tbl.save(validation_tbl_path)  \n",
    "  \n",
    "# Create a Data object for the validation dataset with properties such as path, type, description, and name  \n",
    "validation_data = Data(  \n",
    "    path=validation_tbl_path,    \n",
    "    type=AssetTypes.MLTABLE,    \n",
    "    description=validation_dataset_description,    \n",
    "    name=validation_dataset_name,    \n",
    ")  \n",
    "  \n",
    "# Create or update the validation dataset in Azure ML workspace  \n",
    "validation_dataset = ml_client.data.create_or_update(validation_data)  \n",
    "  \n",
    "# Retrieve the validation data asset information using the dataset name and version  \n",
    "validation_data_asset = ml_client.data.get(name=validation_dataset_name, version=validation_dataset.version)  \n",
    "  \n",
    "# Load the validation data asset into a pandas DataFrame and display the first few rows  \n",
    "mltable.load(f'azureml:/{validation_data_asset.id}').to_pandas_dataframe().head()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802d447-7fa5-40e2-96bf-14af01c955bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name for the training dataset  \n",
    "train_dataset_name = 'TRAIN_BatteryCycles'  \n",
    "  \n",
    "# Provide a description for the training dataset  \n",
    "train_dataset_description = 'Training dataset from battery cycle repo @https://github.com/ignavinuales/Battery_RUL_Prediction'  \n",
    "  \n",
    "# Specify the local path to save the training dataset  \n",
    "train_tbl_path = './train'  \n",
    "  \n",
    "# Define the file path to the training dataset CSV file  \n",
    "train_paths = [{'file':'./train/train_data.csv'}]  \n",
    "  \n",
    "# Load the training dataset from the CSV file into a MLTable  \n",
    "train_tbl = mltable.from_delimited_files(paths=train_paths)  \n",
    "  \n",
    "# Save the MLTable to the specified path  \n",
    "train_tbl.save(train_tbl_path)  \n",
    "  \n",
    "# Create a Data object for the training dataset with properties such as path, type, description, and name  \n",
    "train_data = Data(  \n",
    "    path=train_tbl_path,    \n",
    "    type=AssetTypes.MLTABLE,    \n",
    "    description=train_dataset_description,    \n",
    "    name=train_dataset_name,    \n",
    ")  \n",
    "  \n",
    "# Create or update the training dataset in Azure ML workspace  \n",
    "train_dataset = ml_client.data.create_or_update(train_data)  \n",
    "  \n",
    "# Retrieve the training data asset information using the dataset name and version  \n",
    "train_data_asset = ml_client.data.get(name=train_dataset_name, version=train_dataset.version)  \n",
    "  \n",
    "# Load the training data asset into a pandas DataFrame and display the first few rows  \n",
    "mltable.load(f'azureml:/{train_data_asset.id}').to_pandas_dataframe().head()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e54c5-1fc2-4da5-8b31-7cba0d880347",
   "metadata": {},
   "source": [
    "### Set up and run an AutoML job\n",
    "\n",
    "Note: here you can modify the AutoML task configuration, including number of trials, timeout limits, models to be used/not used, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623190b1-b479-4673-a7b2-0b841874702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input data for the training job using the Azure ML dataset identifier for the training dataset  \n",
    "training_input = Input(path=f'azureml:{train_dataset_name}:{train_dataset.version}')  \n",
    "  \n",
    "# Define the input data for the validation during training using the Azure ML dataset identifier for the validation dataset  \n",
    "validation_input = Input(path=f'azureml:{validation_dataset_name}:{validation_dataset.version}')  \n",
    "  \n",
    "# Configure the AutoML regression job with required parameters like compute target, experiment name, training and validation data  \n",
    "# Also, set the target column name for prediction, the primary metric to evaluate models, and enable model explainability  \n",
    "regression_job = automl.regression(  \n",
    "    compute=cpu_compute_target,  \n",
    "    experiment_name='Battery_Cycle_RUL_Prediction',  \n",
    "    training_data=training_input,  \n",
    "    validation_data=validation_input,  \n",
    "    target_column_name=\"RUL\",  \n",
    "    primary_metric=\"r2_score\",  \n",
    "    enable_model_explainability=True,  \n",
    ")  \n",
    "  \n",
    "# Set limits for the regression job such as total time, time per trial, maximum number of trials, and enable early termination  \n",
    "regression_job.set_limits(  \n",
    "    timeout_minutes=600,   \n",
    "    trial_timeout_minutes=20,   \n",
    "    max_trials=25,  \n",
    "    enable_early_termination=True,  \n",
    ")  \n",
    "  \n",
    "# Set training properties, in this case enabling ONNX compatible models which can be beneficial for cross-platform consistency  \n",
    "regression_job.set_training(  \n",
    "    enable_onnx_compatible_models=True  \n",
    ")  \n",
    "  \n",
    "# Set the featurization mode to 'auto' allowing AutoML to handle feature engineering automatically  \n",
    "regression_job.set_featurization(  \n",
    "    mode='auto'  \n",
    ")  \n",
    "  \n",
    "# Submit the configured AutoML job to the Azure ML workspace and print the job details  \n",
    "returned_job = ml_client.jobs.create_or_update(  \n",
    "    regression_job  \n",
    ")  \n",
    "  \n",
    "print(f\"Created job: {returned_job}\")  \n",
    "  \n",
    "# Retrieve and print the URL for monitoring the status of the submitted job in Azure Machine Learning Studio  \n",
    "returned_job.services[\"Studio\"].endpoint  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335ecda-8226-48bb-9893-aeec1e50037a",
   "metadata": {},
   "source": [
    "### Monitor AutoML job progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2b91d-c043-4a93-b136-6dce31b6675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Import the time module to use the sleep function  \n",
    "  \n",
    "status = ''  # Initialize the status variable as an empty string  \n",
    "  \n",
    "# Start a while loop that will run as long as status is not 'Completed' or 'Failed'  \n",
    "while status != 'Completed' and status != 'Failed':  \n",
    "    # Call the get method on ml_client.jobs using the display_name of the job to get the current status  \n",
    "    status = ml_client.jobs.get(returned_job.display_name).status  \n",
    "    print(status)  # Print the current status  \n",
    "    time.sleep(30)  # Pause the loop for 30 seconds before checking the status again  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9046c65-76b3-41b8-a7e5-89e9d2b170a1",
   "metadata": {},
   "source": [
    "### Retrieve and register best performing model\n",
    "\n",
    "Note: here is a place where you may look to include some custom champion vs. challenger logic prior to registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536a120-1026-42fe-acaf-159fb0ce5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow  \n",
    "from mlflow.tracking.client import MlflowClient  # Import MlflowClient for tracking ML experiments  \n",
    "from mlflow.artifacts import download_artifacts  # Import download_artifacts for managing artifacts  \n",
    "  \n",
    "# Obtain the tracking URL from MLClient  \n",
    "# This retrieves the MLflow tracking URL for the current workspace from MLClient  \n",
    "mlflow_tracking_uri = ml_client.workspaces.get(  \n",
    "    name=ml_client.workspace_name  \n",
    ").mlflow_tracking_uri  \n",
    "  \n",
    "# Print out the obtained MLflow tracking URI  \n",
    "print(mlflow_tracking_uri)  \n",
    "  \n",
    "# Set the tracking URI for MLflow,   \n",
    "# This ensures that MLflow logs to the correct tracking server  \n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)  \n",
    "  \n",
    "# Print the current tracking URI to verify it's been set correctly  \n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))  \n",
    "  \n",
    "# Initialize the MLFlow client  \n",
    "# This creates an instance of MlflowClient which will be used to interact with the MLflow tracking server  \n",
    "mlflow_client = MlflowClient()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544522c-f423-43a1-9795-cd9d76af6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parent run  \n",
    "# This retrieves the details of the parent run from MLflow using the display name of the job  \n",
    "mlflow_parent_run = mlflow_client.get_run(returned_job.display_name)  \n",
    "  \n",
    "# Print information about the parent run for verification  \n",
    "print(\"Parent Run: \")  \n",
    "print(mlflow_parent_run)  # Print the entire parent run object  \n",
    "print(mlflow_parent_run.data.tags)  # Specifically print the tags associated with the parent run  \n",
    "  \n",
    "# Get the best model's child run  \n",
    "# Extract the ID of the best child run from the tags of the parent run  \n",
    "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]  \n",
    "# Print the retrieved best child run ID  \n",
    "print(\"Found best child run id: \", best_child_run_id)  \n",
    "  \n",
    "# Retrieve the best child run's details using its ID  \n",
    "best_run = mlflow_client.get_run(best_child_run_id)  \n",
    "  \n",
    "# Print information about the best child run for verification  \n",
    "print(\"Best child run: \")  \n",
    "print(best_run)  # Print the entire best child run object  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e590bc2-c4ab-49de-af8f-27b1082ac5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model name to be used for the registered model  \n",
    "model_name = \"battery-cycle-rul-prediction\"  \n",
    "  \n",
    "# Create a Model object with the path to the MLflow model artifacts from the best run,  \n",
    "# the name for the model, a description, and the type specifying it's an MLflow model  \n",
    "model = Model(  \n",
    "    path=f\"azureml://jobs/{best_run.info.run_id}/outputs/artifacts/outputs/mlflow-model/\", # Path to the model artifacts  \n",
    "    name=model_name,  # Name for the model  \n",
    "    description=\"Regression model for predicting remaining useful life of a battery based on current cycle data\", # Description of the model purpose  \n",
    "    type=AssetTypes.MLFLOW_MODEL,  # Type of the model, indicating it's an MLflow model  \n",
    ")  \n",
    "  \n",
    "# Register the model in Azure Machine Learning workspace or update if it already exists  \n",
    "# This step makes the model available for deployment and further tracking  \n",
    "registered_model = ml_client.models.create_or_update(model)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f4cb0-dede-43b1-ac02-f9c7f608921d",
   "metadata": {},
   "source": [
    "### Retrieve a copy of the best performing model and download locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbc473-ee36-4e4f-bf2e-b1cdc5368a38",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create local folder  \n",
    "# Define the local directory path where artifacts will be downloaded  \n",
    "local_dir = \"./artifact_downloads\"  \n",
    "# Check if the local directory exists, and if not, create it  \n",
    "if not os.path.exists(local_dir):  \n",
    "    os.mkdir(local_dir)  \n",
    "      \n",
    "# Download run's artifacts/outputs  \n",
    "# Download the artifacts associated with the specified run ID and save them to the local directory  \n",
    "local_path = download_artifacts(  \n",
    "    run_id=best_run.info.run_id,  # The run ID of the best child run  \n",
    "    artifact_path=\"outputs\",  # The artifact path within the run to download  \n",
    "    dst_path=local_dir  # The destination path where artifacts will be saved locally  \n",
    ")  \n",
    "# Print the local path where artifacts were downloaded to confirm the action  \n",
    "print(\"Artifacts downloaded in: {}\".format(local_path))  \n",
    "# List the contents of the downloaded artifacts directory and print them out  \n",
    "print(\"Artifacts: {}\".format(os.listdir(local_path)))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c448e-6efe-4cda-a9c9-e3001151f6a5",
   "metadata": {},
   "source": [
    "### Create a reusable environment based on the conda YAML definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f62ade-a4a5-4da3-993e-f743fd61d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or update the environment for deployment  \n",
    "# This sets up an environment with the necessary dependencies for the model to run  \n",
    "  \n",
    "base_environment = ml_client.environments.create_or_update(  \n",
    "    Environment(  \n",
    "        name=f\"{model_name}-env\",  # Define a name for the environment, typically related to the model name  \n",
    "        image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu22.04\",  # Specify the Docker image to use as a base for the environment  \n",
    "        conda_file=\"./artifact_downloads/outputs/conda_env_v_1_0_0.yml\",  # Point to the conda environment file that lists all dependencies  \n",
    "    )  \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea03129-171b-46e0-baa6-b2fc0d25eadc",
   "metadata": {},
   "source": [
    "### Create a local deployment of the model (running inside docker) for inferencing\n",
    "\n",
    "Here we can use our model in a managed online endpoint (running locally on our compute instance). If the model performs as expected, we can optionally update our deployment to target cloud resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9bdaa-389e-416b-bbc5-0a231da002a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name for the online endpoint  \n",
    "endpoint_name = 'battery-cycle-rul-endpoint'  \n",
    "  \n",
    "# Create an instance of ManagedOnlineEndpoint with the specified name  \n",
    "endpoint = ManagedOnlineEndpoint(name=endpoint_name)  \n",
    "  \n",
    "# Begin the process of creating or updating the online endpoint  \n",
    "# This is an asynchronous operation that will run locally  \n",
    "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)  \n",
    "  \n",
    "# Define a name for the deployment that is for local model testing  \n",
    "deployment_name = \"local-model-testing\"  \n",
    "  \n",
    "# Create a deployment package with the model, environment, and code configuration  \n",
    "deployment_package = ManagedOnlineDeployment(  \n",
    "    name=deployment_name,  # Set the name of the deployment  \n",
    "    endpoint_name=endpoint_name,  # Associate the deployment with the endpoint created earlier  \n",
    "    model=f'azureml:{registered_model.name}:{registered_model.version}',  # Define the model to deploy using the registered model name and version  \n",
    "    environment=base_environment,  # Set the environment for the deployment with all necessary dependencies  \n",
    "    code_configuration=CodeConfiguration(  \n",
    "        code=\"./artifact_downloads/outputs\",  # Specify the directory where the code is located  \n",
    "        scoring_script=\"scoring_file_v_1_0_0.py\"  # Identify the scoring script that will be used for inference  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "# Begin the process of creating or updating the deployment package  \n",
    "# This is also an asynchronous operation that will run locally  \n",
    "ml_client.online_deployments.begin_create_or_update(deployment_package, local=True)  \n",
    "  \n",
    "# Retrieve the updated endpoint details  \n",
    "endpoint = ml_client.online_endpoints.get(endpoint_name, local=True)  \n",
    "  \n",
    "# Get the scoring URI from the endpoint which can be used to send scoring requests  \n",
    "scoring_uri = endpoint.scoring_uri  \n",
    "  \n",
    "# Print out the scoring URI  \n",
    "print(scoring_uri)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d86b992-7579-443e-b766-92757f0cafbc",
   "metadata": {},
   "source": [
    "### Submit a request to local endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be5bd7-0ad3-424d-983f-7ba70a203efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # Import requests library to make HTTP requests  \n",
    "import json  # Import json library for parsing JSON  \n",
    "  \n",
    "# Prepare the data frame for sending to the scoring endpoint  \n",
    "hold_df = validation_df  # Assign the validation dataframe to hold_df  \n",
    "hold_df = hold_df.reset_index()  # Reset index to ensure proper JSON formatting  \n",
    "hold_df = hold_df.drop(columns=['RUL', 'index'])  # Drop 'RUL' and 'index' columns as they are not needed for prediction  \n",
    "  \n",
    "# Send a POST request to the scoring URI with the data to get predictions  \n",
    "# Convert the dataframe to JSON format and specify the correct content type  \n",
    "resp = requests.post(  \n",
    "    scoring_uri,  \n",
    "    data=json.dumps({'data': hold_df.to_dict(orient='records')}),  # Convert dataframe to dictionary and then to JSON string  \n",
    "    headers={'Content-Type': 'application/json'}  # Set the header to indicate JSON content  \n",
    ")  \n",
    "  \n",
    "# Parse the JSON response to extract the predictions  \n",
    "result = json.loads(resp.json())['result']  # Load JSON response and extract the 'result' field which contains predictions  \n",
    "  \n",
    "# Create a new dataframe with the predicted Remaining Useful Life (RUL)  \n",
    "result_df = validation_df  # Use the original validation dataframe  \n",
    "result_df = result_df.reset_index()  # Reset index for proper alignment  \n",
    "result_df['Predicted RUL'] = result  # Add a new column with predicted RUL values  \n",
    "  \n",
    "# Display the dataframe with predictions  \n",
    "result_df  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8ad4eb-c1cd-43c2-8a6e-910782de9735",
   "metadata": {},
   "source": [
    "### Plot actual RUL vs. predicted RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30807536-9e77-45b2-a44c-002d390ea1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Import the matplotlib library for plotting  \n",
    "  \n",
    "# Create a scatter plot to compare actual RUL vs predicted RUL  \n",
    "plt.scatter(  \n",
    "    result_df['RUL'],  # X-axis data: Actual RUL values from result_df  \n",
    "    result_df['Predicted RUL']  # Y-axis data: Predicted RUL values from result_df  \n",
    ")  \n",
    "  \n",
    "# Label the X-axis as 'Actual RUL'  \n",
    "plt.xlabel('Actual RUL')  \n",
    "  \n",
    "# Label the Y-axis as 'Predicted RUL'  \n",
    "plt.ylabel('Predicted RUL')  \n",
    "  \n",
    "# Display the plot  \n",
    "plt.show()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
